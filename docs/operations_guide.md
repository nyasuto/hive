# ğŸ›¡ï¸ Beehive é‹ç”¨ã‚¬ã‚¤ãƒ‰

Claude Multi-Agent Development System ã®æœ¬ç•ªé‹ç”¨ãƒ»ç›£è¦–ãƒ»ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ ç›®æ¬¡

- [ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–](#ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–)
- [ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯](#ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯)
- [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†)
- [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
- [é‹ç”¨è‡ªå‹•åŒ–](#é‹ç”¨è‡ªå‹•åŒ–)
- [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–)

---

## ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–

### 1. åŸºæœ¬ç›£è¦–é …ç›®

#### Beehive ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹

```bash
# ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“çŠ¶æ…‹ç¢ºèª
./beehive.sh status

# è©³ç´°çŠ¶æ…‹ï¼ˆJSONå½¢å¼ï¼‰
python -c "
from bees.queen_bee import QueenBee
queen = QueenBee('queen')
import json
status = queen.get_system_status()
print(json.dumps(status, indent=2, ensure_ascii=False))
"
```

#### tmux ã‚»ãƒƒã‚·ãƒ§ãƒ³ç›£è¦–

```bash
# ã‚»ãƒƒã‚·ãƒ§ãƒ³å­˜åœ¨ç¢ºèª
tmux has-session -t beehive 2>/dev/null && echo "âœ… Active" || echo "âŒ Inactive"

# ãƒšã‚¤ãƒ³çŠ¶æ…‹ç¢ºèª
tmux list-panes -t beehive -F "#{pane_id}: #{pane_title} (#{pane_width}x#{pane_height})"

# å„ãƒšã‚¤ãƒ³ã®ç”Ÿå­˜ç¢ºèª
for pane in 0.0 0.1 0.2 0.3; do
    tmux send-keys -t beehive:$pane "echo 'heartbeat-$(date)'" C-m
done
```

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç›£è¦–

#### æ¥ç¶šãƒ»æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯

```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
ls -la hive/hive_memory.db

# åŸºæœ¬æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
sqlite3 hive/hive_memory.db "PRAGMA integrity_check;"

# ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª
sqlite3 hive/hive_memory.db ".tables"
```

#### ãƒ‡ãƒ¼ã‚¿ç›£è¦–ã‚¯ã‚¨ãƒª

```sql
-- ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¹ã‚¯æ•°
SELECT status, COUNT(*) as count 
FROM tasks 
GROUP BY status;

-- BeeçŠ¶æ…‹ç¢ºèª
SELECT bee_name, status, last_heartbeat, 
       (julianday('now') - julianday(last_heartbeat)) * 1440 as minutes_since_heartbeat
FROM bee_states;

-- æœªå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°
SELECT to_bee, COUNT(*) as unprocessed_count
FROM bee_messages 
WHERE processed = FALSE 
GROUP BY to_bee;

-- send-keysé€šä¿¡ãƒ­ã‚°ï¼ˆæœ€æ–°10ä»¶ï¼‰
SELECT timestamp, session_name, pane_id, 
       substr(message_content, 1, 50) as message_preview
FROM send_keys_log 
ORDER BY timestamp DESC 
LIMIT 10;
```

### 3. ãƒ­ã‚°ç›£è¦–

#### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ç›£è¦–

```bash
# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚°ç›£è¦–
tail -f logs/beehive.log | jq -r '.timestamp + " [" + .level + "] " + .message'

# ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚£ãƒ«ã‚¿
tail -f logs/beehive.log | grep -E "(ERROR|CRITICAL)" | jq .

# ç‰¹å®šBeeã®ãƒ­ã‚°ãƒ•ã‚£ãƒ«ã‚¿
tail -f logs/beehive.log | jq 'select(.bee_name == "queen")'
```

#### ãƒ­ã‚°è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
#!/usr/bin/env python3
# scripts/log_analyzer.py
import json
import sys
from datetime import datetime, timedelta
from collections import Counter

def analyze_logs(log_file_path, hours=24):
    """ãƒ­ã‚°è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
    cutoff_time = datetime.now() - timedelta(hours=hours)
    
    error_counts = Counter()
    bee_activity = Counter()
    event_types = Counter()
    
    with open(log_file_path) as f:
        for line in f:
            try:
                log = json.loads(line)
                log_time = datetime.fromisoformat(log['timestamp'])
                
                if log_time < cutoff_time:
                    continue
                
                # ã‚¨ãƒ©ãƒ¼é›†è¨ˆ
                if log['level'] in ['ERROR', 'CRITICAL']:
                    error_counts[log.get('message', 'Unknown')] += 1
                
                # Beeæ´»å‹•é›†è¨ˆ
                bee_activity[log.get('bee_name', 'unknown')] += 1
                
                # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—é›†è¨ˆ
                if 'event_type' in log:
                    event_types[log['event_type']] += 1
                    
            except (json.JSONDecodeError, KeyError):
                continue
    
    print(f"ğŸ“Š Log Analysis (Last {hours} hours)")
    print(f"ğŸ”´ Errors: {sum(error_counts.values())}")
    print(f"ğŸ“ˆ Bee Activity: {dict(bee_activity)}")
    print(f"ğŸ¯ Top Events: {dict(event_types.most_common(5))}")
    
    if error_counts:
        print(f"âš ï¸  Top Errors:")
        for error, count in error_counts.most_common(5):
            print(f"  {count}x: {error[:80]}")

if __name__ == "__main__":
    log_path = sys.argv[1] if len(sys.argv) > 1 else "logs/beehive.log"
    analyze_logs(log_path)
```

---

## ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

### 1. è‡ªå‹•ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

#### ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/health_check.sh

echo "ğŸ¥ Beehive Health Check - $(date)"
echo "================================"

# 1. tmux ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¢ºèª
if tmux has-session -t beehive 2>/dev/null; then
    echo "âœ… tmux session: Active"
else
    echo "âŒ tmux session: Inactive"
    exit 1
fi

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
if python -c "import sqlite3; sqlite3.connect('hive/hive_memory.db').execute('SELECT 1').fetchone()" 2>/dev/null; then
    echo "âœ… Database: Accessible"
else
    echo "âŒ Database: Connection failed"
    exit 1
fi

# 3. BeeçŠ¶æ…‹ç¢ºèª
dead_bees=$(sqlite3 hive/hive_memory.db "
SELECT COUNT(*) FROM bee_states 
WHERE (julianday('now') - julianday(last_heartbeat)) * 1440 > 10
")

if [ "$dead_bees" -eq 0 ]; then
    echo "âœ… Bee heartbeats: All active"
else
    echo "âš ï¸  Bee heartbeats: $dead_bees bees silent >10min"
fi

# 4. ãƒ­ã‚°ã‚¨ãƒ©ãƒ¼ç¢ºèª
recent_errors=$(tail -n 100 logs/beehive.log | grep -c "ERROR\|CRITICAL" || echo 0)
if [ "$recent_errors" -lt 5 ]; then
    echo "âœ… Recent errors: $recent_errors (acceptable)"
else
    echo "âš ï¸  Recent errors: $recent_errors (investigate)"
fi

# 5. æœªå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç¢ºèª
unprocessed_messages=$(sqlite3 hive/hive_memory.db "
SELECT COUNT(*) FROM bee_messages WHERE processed = FALSE
")

if [ "$unprocessed_messages" -lt 10 ]; then
    echo "âœ… Unprocessed messages: $unprocessed_messages"
else
    echo "âš ï¸  Unprocessed messages: $unprocessed_messages (backlog)"
fi

echo "================================"
echo "ğŸ¯ Health check completed"
```

### 2. ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹

#### ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç›£è¦–

```python
#!/usr/bin/env python3
# scripts/system_metrics.py
import psutil
import sqlite3
import json
from datetime import datetime

def collect_system_metrics():
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
    metrics = {
        "timestamp": datetime.now().isoformat(),
        "system": {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage('/').percent
        },
        "processes": [],
        "database": {}
    }
    
    # Claudeãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–
    for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
        if 'claude' in proc.info['name'].lower():
            metrics["processes"].append(proc.info)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º
    try:
        import os
        db_size = os.path.getsize("hive/hive_memory.db")
        metrics["database"]["size_mb"] = db_size / (1024 * 1024)
        
        # ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
        conn = sqlite3.connect("hive/hive_memory.db")
        for table in ["tasks", "bee_messages", "bee_states", "send_keys_log"]:
            cursor = conn.execute(f"SELECT COUNT(*) FROM {table}")
            metrics["database"][f"{table}_count"] = cursor.fetchone()[0]
        conn.close()
        
    except Exception as e:
        metrics["database"]["error"] = str(e)
    
    return metrics

if __name__ == "__main__":
    metrics = collect_system_metrics()
    print(json.dumps(metrics, indent=2))
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†

### 1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

#### å¿œç­”æ™‚é–“æ¸¬å®š

```python
#!/usr/bin/env python3
# scripts/performance_test.py
import time
import statistics
from bees.queen_bee import QueenBee

def measure_response_times():
    """å„æ“ä½œã®å¿œç­”æ™‚é–“æ¸¬å®š"""
    queen = QueenBee("queen")
    
    # ã‚¿ã‚¹ã‚¯ä½œæˆå¿œç­”æ™‚é–“
    task_creation_times = []
    for i in range(10):
        start = time.time()
        task_id = queen.create_task(
            f"Performance test task {i}",
            "Test task for performance measurement",
            "low"
        )
        end = time.time()
        task_creation_times.append(end - start)
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å¿œç­”æ™‚é–“
    message_times = []
    for i in range(10):
        start = time.time()
        queen.send_message(
            "developer",
            "test",
            f"Performance test {i}",
            "Test message content"
        )
        end = time.time()
        message_times.append(end - start)
    
    print("ğŸ“Š Performance Metrics")
    print(f"Task Creation - Avg: {statistics.mean(task_creation_times):.3f}s, Max: {max(task_creation_times):.3f}s")
    print(f"Message Send - Avg: {statistics.mean(message_times):.3f}s, Max: {max(message_times):.3f}s")

if __name__ == "__main__":
    measure_response_times()
```

### 2. è² è·å¯¾ç­–

#### åŒæ™‚å®Ÿè¡Œåˆ¶å¾¡

```python
# bees/performance_manager.py
import asyncio
import threading
from typing import Dict, Any
from datetime import datetime, timedelta

class PerformanceManager:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.operation_counts = {}
        self.rate_limits = {
            "task_creation": {"max": 10, "window": 60},  # 1åˆ†é–“ã«10ã‚¿ã‚¹ã‚¯ã¾ã§
            "message_send": {"max": 50, "window": 60},   # 1åˆ†é–“ã«50ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ã§
        }
        self.lock = threading.Lock()
    
    def check_rate_limit(self, operation: str) -> bool:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯"""
        with self.lock:
            now = datetime.now()
            
            if operation not in self.operation_counts:
                self.operation_counts[operation] = []
            
            # å¤ã„è¨˜éŒ²ã‚’å‰Šé™¤
            cutoff = now - timedelta(seconds=self.rate_limits[operation]["window"])
            self.operation_counts[operation] = [
                ts for ts in self.operation_counts[operation] if ts > cutoff
            ]
            
            # åˆ¶é™ãƒã‚§ãƒƒã‚¯
            if len(self.operation_counts[operation]) >= self.rate_limits[operation]["max"]:
                return False
            
            # è¨˜éŒ²è¿½åŠ 
            self.operation_counts[operation].append(now)
            return True

# ä½¿ç”¨ä¾‹
performance_manager = PerformanceManager()

def rate_limited_task_creation(queen, title, description):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã‚¿ã‚¹ã‚¯ä½œæˆ"""
    if not performance_manager.check_rate_limit("task_creation"):
        raise Exception("Rate limit exceeded for task creation")
    
    return queen.create_task(title, description)
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. ä¸€èˆ¬çš„ãªå•é¡Œã¨å¯¾å‡¦æ³•

#### tmux ã‚»ãƒƒã‚·ãƒ§ãƒ³å•é¡Œ

```bash
# å•é¡Œ: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå¿œç­”ã—ãªã„
# è¨ºæ–­
tmux list-sessions
tmux list-panes -t beehive
tmux capture-pane -t beehive:0.0 -p

# å¯¾å‡¦: æ®µéšçš„å¾©æ—§
# 1. å¼·åˆ¶çµ‚äº†ãƒ»å†ä½œæˆ
tmux kill-session -t beehive
./beehive.sh init

# 2. å€‹åˆ¥ãƒšã‚¤ãƒ³å†èµ·å‹•
tmux send-keys -t beehive:0.0 C-c
tmux send-keys -t beehive:0.0 "claude --dangerously-skip-permissions" C-m
```

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å•é¡Œ

```bash
# å•é¡Œ: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç ´æ
# è¨ºæ–­
sqlite3 hive/hive_memory.db "PRAGMA integrity_check;"

# å¯¾å‡¦: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ
cp hive/hive_memory.db hive/hive_memory.db.corrupt
cp backups/hive_memory_$(date +%Y%m%d).db hive/hive_memory.db

# ç·Šæ€¥æ™‚: æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
rm hive/hive_memory.db
python bees/init_test_db.py
```

#### Beeå¿œç­”åœæ­¢

```bash
# å•é¡Œ: ç‰¹å®šBeeãŒå¿œç­”ã—ãªã„
# è¨ºæ–­
sqlite3 hive/hive_memory.db "
SELECT bee_name, last_heartbeat,
       (julianday('now') - julianday(last_heartbeat)) * 1440 as minutes_ago
FROM bee_states 
WHERE bee_name = 'developer';
"

# å¯¾å‡¦: Beeå†èµ·å‹•
# 1. å¯¾è±¡ãƒšã‚¤ãƒ³ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹
tmux select-pane -t beehive:0.1

# 2. ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ãƒ»å†èµ·å‹•
tmux send-keys -t beehive:0.1 C-c
tmux send-keys -t beehive:0.1 "claude --dangerously-skip-permissions" C-m

# 3. å½¹å‰²å†æ³¨å…¥
python -m bees.cli send beehive 0.1 "$(cat roles/developer.md)" --type role_injection
```

### 2. ã‚¨ãƒ©ãƒ¼åˆ†æ

#### ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ

```python
#!/usr/bin/env python3
# scripts/error_analyzer.py
import json
import re
from collections import Counter, defaultdict
from datetime import datetime, timedelta

def analyze_error_patterns(log_file):
    """ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ"""
    errors_by_hour = defaultdict(list)
    error_types = Counter()
    bee_errors = defaultdict(Counter)
    
    with open(log_file) as f:
        for line in f:
            try:
                log = json.loads(line)
                if log['level'] in ['ERROR', 'CRITICAL']:
                    # æ™‚é–“åˆ¥é›†è¨ˆ
                    hour = datetime.fromisoformat(log['timestamp']).hour
                    errors_by_hour[hour].append(log)
                    
                    # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ†é¡
                    message = log['message']
                    if 'database' in message.lower():
                        error_types['database'] += 1
                    elif 'tmux' in message.lower():
                        error_types['tmux'] += 1
                    elif 'timeout' in message.lower():
                        error_types['timeout'] += 1
                    else:
                        error_types['other'] += 1
                    
                    # Beeåˆ¥ã‚¨ãƒ©ãƒ¼
                    bee_name = log.get('bee_name', 'unknown')
                    bee_errors[bee_name][message[:50]] += 1
                    
            except (json.JSONDecodeError, KeyError):
                continue
    
    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    print("ğŸ” Error Pattern Analysis")
    print("=" * 50)
    
    print("ğŸ“Š Errors by Hour:")
    for hour in sorted(errors_by_hour.keys()):
        print(f"  {hour:02d}:00 - {len(errors_by_hour[hour])} errors")
    
    print("\nğŸ“‚ Error Types:")
    for error_type, count in error_types.most_common():
        print(f"  {error_type}: {count}")
    
    print("\nğŸ Errors by Bee:")
    for bee_name, errors in bee_errors.items():
        print(f"  {bee_name}: {sum(errors.values())} total")
        for error, count in errors.most_common(3):
            print(f"    {count}x: {error}")

if __name__ == "__main__":
    analyze_error_patterns("logs/beehive.log")
```

---

## é‹ç”¨è‡ªå‹•åŒ–

### 1. å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="backups"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp hive/hive_memory.db $BACKUP_DIR/hive_memory_$DATE.db

# ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
if [ -f logs/beehive.log ]; then
    cp logs/beehive.log $BACKUP_DIR/beehive_$DATE.log
    > logs/beehive.log  # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªã‚¢
fi

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šï¼‰
find $BACKUP_DIR -name "*.db" -mtime +30 -delete
find $BACKUP_DIR -name "*.log" -mtime +30 -delete

echo "âœ… Backup completed: $DATE"
```

#### å®šæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆcronï¼‰

```bash
# crontab ã‚¨ãƒ³ãƒˆãƒªä¾‹

# 5åˆ†ã”ã¨ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
*/5 * * * * /path/to/hive/scripts/health_check.sh >> /var/log/beehive_health.log 2>&1

# æ¯æ™‚ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
0 * * * * /path/to/hive/scripts/system_metrics.py >> /var/log/beehive_metrics.log 2>&1

# æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
0 2 * * * /path/to/hive/scripts/backup.sh >> /var/log/beehive_backup.log 2>&1

# é€±æ¬¡ãƒ­ã‚°è§£æ
0 3 * * 0 /path/to/hive/scripts/log_analyzer.py logs/beehive.log > /var/log/beehive_weekly_analysis.log
```

### 2. ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

#### ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
#!/usr/bin/env python3
# scripts/alert_manager.py
import smtplib
import json
from email.mime.text import MIMEText
from datetime import datetime
import subprocess

class AlertManager:
    """ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_file="alert_config.json"):
        with open(config_file) as f:
            self.config = json.load(f)
    
    def check_critical_conditions(self):
        """é‡è¦ãªçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        alerts = []
        
        # tmuxã‚»ãƒƒã‚·ãƒ§ãƒ³ç¢ºèª
        try:
            subprocess.run(["tmux", "has-session", "-t", "beehive"], 
                         check=True, capture_output=True)
        except subprocess.CalledProcessError:
            alerts.append({
                "level": "CRITICAL",
                "message": "Beehive tmux session is down",
                "timestamp": datetime.now().isoformat()
            })
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
        try:
            import sqlite3
            conn = sqlite3.connect("hive/hive_memory.db", timeout=5)
            conn.execute("SELECT 1").fetchone()
            conn.close()
        except Exception as e:
            alerts.append({
                "level": "CRITICAL", 
                "message": f"Database connection failed: {e}",
                "timestamp": datetime.now().isoformat()
            })
        
        return alerts
    
    def send_alert(self, alert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        if self.config.get("email_enabled"):
            self._send_email_alert(alert)
        
        if self.config.get("webhook_enabled"):
            self._send_webhook_alert(alert)
    
    def _send_email_alert(self, alert):
        """ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        msg = MIMEText(f"""
Beehive System Alert
        
Level: {alert['level']}
Message: {alert['message']}
Time: {alert['timestamp']}
        """)
        
        msg['Subject'] = f"[Beehive Alert] {alert['level']}: {alert['message'][:50]}"
        msg['From'] = self.config['email']['from']
        msg['To'] = self.config['email']['to']
        
        server = smtplib.SMTP(self.config['email']['smtp_server'])
        server.send_message(msg)
        server.quit()

if __name__ == "__main__":
    alert_manager = AlertManager()
    alerts = alert_manager.check_critical_conditions()
    
    for alert in alerts:
        alert_manager.send_alert(alert)
        print(f"ğŸš¨ Alert sent: {alert['level']} - {alert['message']}")
```

---

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–

### 1. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯

#### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/security_audit.sh

echo "ğŸ”’ Beehive Security Audit - $(date)"
echo "================================"

# 1. ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ç¢ºèª
echo "ğŸ“‹ File Permissions:"
ls -la hive/hive_memory.db
ls -la logs/
ls -la scripts/

# 2. ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
echo -e "\nğŸ” Running Processes:"
ps aux | grep -E "(claude|tmux|beehive)" | grep -v grep

# 3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šç¢ºèª
echo -e "\nğŸŒ Network Connections:"
netstat -tulpn | grep -E ":80|:443|:22" || echo "No suspicious connections"

# 4. ãƒ­ã‚°å†…ã®æ©Ÿå¯†æƒ…å ±ç¢ºèª
echo -e "\nğŸ•µï¸ Checking for secrets in logs:"
if grep -iE "(password|token|key|secret)" logs/beehive.log; then
    echo "âš ï¸ Potential secrets found in logs"
else
    echo "âœ… No obvious secrets in logs"
fi

# 5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®æ©Ÿå¯†æƒ…å ±ç¢ºèª
echo -e "\nğŸ—„ï¸ Checking database for sensitive data:"
sqlite3 hive/hive_memory.db "
SELECT 'Tasks' as table_name, COUNT(*) as count FROM tasks WHERE description LIKE '%password%' OR description LIKE '%secret%'
UNION ALL
SELECT 'Messages' as table_name, COUNT(*) as count FROM bee_messages WHERE content LIKE '%password%' OR content LIKE '%secret%'
"

echo "================================"
echo "ğŸ”’ Security audit completed"
```

### 2. ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡

#### æ¨©é™ç®¡ç†

```bash
# ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™è¨­å®š
chmod 700 hive/                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
chmod 600 hive/hive_memory.db      # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«
chmod 640 logs/beehive.log          # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
chmod 750 scripts/*.sh             # å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# æ‰€æœ‰è€…è¨­å®š
chown -R beehive:beehive hive/
chown -R beehive:beehive logs/
```

### 3. ãƒ‡ãƒ¼ã‚¿ä¿è­·

#### æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿å‰Šé™¤

```python
#!/usr/bin/env python3
# scripts/data_sanitizer.py
import sqlite3
import re

def sanitize_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ©Ÿå¯†æƒ…å ±ã‚’å‰Šé™¤"""
    conn = sqlite3.connect("hive/hive_memory.db")
    
    # æ©Ÿå¯†æƒ…å ±ãƒ‘ã‚¿ãƒ¼ãƒ³
    sensitive_patterns = [
        r'password\s*[:=]\s*\S+',
        r'token\s*[:=]\s*\S+',
        r'api[_-]?key\s*[:=]\s*\S+',
        r'secret\s*[:=]\s*\S+'
    ]
    
    # ã‚¿ã‚¹ã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    cursor = conn.execute("SELECT task_id, description FROM tasks")
    for task_id, description in cursor.fetchall():
        if description:
            sanitized = description
            for pattern in sensitive_patterns:
                sanitized = re.sub(pattern, '[REDACTED]', sanitized, flags=re.IGNORECASE)
            
            if sanitized != description:
                conn.execute(
                    "UPDATE tasks SET description = ? WHERE task_id = ?",
                    (sanitized, task_id)
                )
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    cursor = conn.execute("SELECT message_id, content FROM bee_messages")
    for message_id, content in cursor.fetchall():
        if content:
            sanitized = content
            for pattern in sensitive_patterns:
                sanitized = re.sub(pattern, '[REDACTED]', sanitized, flags=re.IGNORECASE)
            
            if sanitized != content:
                conn.execute(
                    "UPDATE bee_messages SET content = ? WHERE message_id = ?",
                    (sanitized, message_id)
                )
    
    conn.commit()
    conn.close()
    print("âœ… Database sanitization completed")

if __name__ == "__main__":
    sanitize_database()
```

---

## ğŸ“š é‹ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯
- [ ] ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª (`./beehive.sh status`)
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç¢ºèª (`grep ERROR logs/beehive.log`)
- [ ] ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ç¢ºèª
- [ ] Beeå¿œç­”ç¢ºèª

### é€±æ¬¡ãƒã‚§ãƒƒã‚¯
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°ç¢ºèª
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‹•ä½œç¢ºèª

### æœˆæ¬¡ãƒã‚§ãƒƒã‚¯
- [ ] ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
- [ ] å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
- [ ] ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»å®Ÿè¡Œ

---

## ğŸš¨ ç·Šæ€¥å¯¾å¿œæ‰‹é †

### 1. ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨åœæ­¢æ™‚

```bash
# 1. ç¾çŠ¶ç¢ºèª
./beehive.sh status
tmux list-sessions

# 2. å¼·åˆ¶åœæ­¢ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
tmux kill-session -t beehive
pkill -f claude

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp hive/hive_memory.db backups/emergency_backup_$(date +%Y%m%d_%H%M%S).db

# 4. ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•
./beehive.sh init

# 5. å‹•ä½œç¢ºèª
./beehive.sh status
```

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç ´ææ™‚

```bash
# 1. ç ´æãƒ•ã‚¡ã‚¤ãƒ«é€€é¿
mv hive/hive_memory.db hive/hive_memory.db.corrupt

# 2. æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©å…ƒ
cp backups/hive_memory_$(ls backups/ | grep hive_memory | tail -1) hive/hive_memory.db

# 3. æ•´åˆæ€§ç¢ºèª
sqlite3 hive/hive_memory.db "PRAGMA integrity_check;"

# 4. ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•
./beehive.sh stop
./beehive.sh init
```

---

## ğŸ“ ã‚µãƒãƒ¼ãƒˆãƒ»ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

### 1. ãƒ­ã‚°åé›†

```bash
# ç·Šæ€¥æ™‚ãƒ­ã‚°ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆ
tar -czf beehive_emergency_$(date +%Y%m%d_%H%M%S).tar.gz \
    logs/ \
    hive/hive_memory.db \
    scripts/health_check.sh \
    --exclude="*.tmp"
```

### 2. å•é¡Œå ±å‘Šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
## Beehive å•é¡Œå ±å‘Š

**ç™ºç”Ÿæ™‚åˆ»**: YYYY-MM-DD HH:MM:SS
**ç—‡çŠ¶**: [å•é¡Œã®è©³ç´°èª¬æ˜]
**å½±éŸ¿ç¯„å›²**: [å½±éŸ¿ã‚’å—ã‘ã‚‹Beeãƒ»æ©Ÿèƒ½]
**å†ç¾æ‰‹é †**: 
1. [æ‰‹é †1]
2. [æ‰‹é †2]

**ãƒ­ã‚°æƒ…å ±**:
```bash
# æœ€æ–°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
tail -n 50 logs/beehive.log | grep ERROR

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
./beehive.sh status
```

**å®Ÿè¡Œã—ãŸå¯¾å‡¦**:
- [å¯¾å‡¦å†…å®¹1]
- [å¯¾å‡¦å†…å®¹2]

**æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«**: beehive_emergency_YYYYMMDD_HHMMSS.tar.gz
```

---

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

### ğŸ› ï¸ æŠ€è¡“ç†è§£
- **[é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](developer_guide.md#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç†è§£)** - ã‚·ã‚¹ãƒ†ãƒ æ§‹é€ ã®è©³ç´°ç†è§£
- **[API Reference](api_reference.md)** - ç›£è¦–ãƒ»è¨ºæ–­APIä»•æ§˜

### ğŸ“ å­¦ç¿’ãƒ»ç ”ä¿®
- **[ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](tutorial.md)** - åŸºæœ¬æ“ä½œã®ä½“é¨“å­¦ç¿’ï¼ˆ3-4æ™‚é–“ï¼‰
- **[é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰ãƒ‡ãƒãƒƒã‚°](developer_guide.md#ãƒ‡ãƒãƒƒã‚°ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)** - é–‹ç™ºè¦–ç‚¹ã®ãƒˆãƒ©ãƒ–ãƒ«å¯¾å¿œ

### ğŸ”— ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
- **[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç›®æ¬¡](README.md)** - å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¦‚è¦ãƒ»å¯¾è±¡èª­è€…åˆ¥ã‚¬ã‚¤ãƒ‰

### ğŸ“ ç·Šæ€¥æ™‚å‚ç…§
- **[API Reference ä¾‹å¤–ã‚¯ãƒ©ã‚¹](api_reference.md#ä¾‹å¤–ã‚¯ãƒ©ã‚¹)** - ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ãƒ»å¯¾å‡¦æ³•
- **[é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰ä¸€èˆ¬çš„å•é¡Œ](developer_guide.md#ä¸€èˆ¬çš„ãªå•é¡Œã¨å¯¾å‡¦æ³•)** - é–‹ç™ºç’°å¢ƒã§ã®é¡ä¼¼å•é¡Œ

---

**ğŸ”„ æœ€çµ‚æ›´æ–°**: 2025-07-23  
**ğŸ“‹ å¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v1.0.0  
**ğŸ¯ æƒ³å®šèª­è€…**: ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ãƒ»é‹ç”¨æ‹…å½“è€…